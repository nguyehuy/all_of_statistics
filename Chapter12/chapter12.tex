\documentclass[10pt]{article}
 
\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb, graphicx, multicol, array}
 
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
 
\newenvironment{problem}[2][Problem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}



\begin{document}
\title{Chapter 12}
\author{Huy Nguyen, Hoang Nguyen}
\maketitle
    
\begin{problem}{1}

a) 

\[X \sim Binomial(n, p) \Rightarrow f(x|p)= \begin{pmatrix}
n\\
X
\end{pmatrix} p^x (1-p)^{n-x} \propto p^x(1-p)^{n-x} \] 
\[\Rightarrow \pi (p|x)= f(x|p)f(p) \propto p^x(1-p)^{n-x}p^{\alpha -1}(1-p)^{\beta -1} =p^{\alpha + x -1}(1-p)^{n-x+\beta -1}\]
\[\Rightarrow p|x \sim Beta(\alpha+x, n-x+\beta)\]
Hence, Bayes estimator:
\[\hat{p}= \mathbb{E}[p|x]= \frac{x+\alpha}{n-x+\beta + x+ \alpha}= \frac{x+\alpha}{n+\alpha +\beta}\]
Under least mean square:
\[R(\hat{p}, p)= Var(\hat{p})+ (p-\mathbb{E}[\hat{p}])^2=\frac{Var(x)}{(n+\alpha + \beta)^2}+ \big( p-\frac{\mathbb{E}[x]+\alpha}{n+ \alpha + \beta}\big)^2= \frac{np(1-p)}{(n+ \alpha + \beta)^2} + \frac{(p(\alpha + \beta)-\alpha)^2}{(n+ \alpha + \beta)^2}\]
Hence, Bayes risk :
\[r(f, \hat{p})= \mathbb{E}_f [R(p, \hat{p})]= \mathbb{E}_f \big [ \frac{np(1-p)}{(n+ \alpha + \beta)^2} \big] + \mathbb{E}_f \big [ \frac{(p(\alpha + \beta)-\alpha)^2}{(n+ \alpha + \beta)^2} \big ]=\frac{n\alpha \beta}{(\alpha + \beta)^2 (n+ \alpha + \beta)^2}\]
b) 
\[X \sim Poison(\alpha) \Rightarrow f(x|\alpha) \propto  \lambda ^x e^{-\lambda}\]
\[ \Rightarrow \pi (\lambda | x) \propto \lambda ^x e^{-\lambda} \lambda ^{\alpha -1} e^{-\beta \lambda}= \lambda ^{x+\lambda -1} e^ {-\lambda (\beta + 1)}\]
\[\Rightarrow \lambda|x \sim Gamma(x+\lambda, \beta + 1) \Rightarrow \hat{\lambda}=\frac{x+\lambda}{\beta + 1}\]

Similarly from above question, we get:
\[R(\hat{\lambda}, \lambda)=\frac{\lambda + \alpha}{(\beta +1)^2} +\frac{(\alpha -\lambda \beta)^2}{(\beta +1)^2}\]
\[\Rightarrow r(f, \hat{\lambda})= \mathbb{E}_f[R(\hat{\lambda}, \lambda)]= \frac{\lambda}{\beta (\beta +1)^2}\]
c) 
Similarly from above questions, we get:
\[\theta | x \sim \mathbb{N}\big( \frac{b^2}{\sigma ^2 + b^2}x+\frac{\sigma ^2}{\sigma ^2 + b^2}a,(\frac{1}{\sigma ^2}+ \frac{1}{b^2})^{-1}\big) \Rightarrow \hat{\theta}= \frac{b^2}{\sigma ^2 + b^2}x+\frac{\sigma ^2}{\sigma ^2 + b^2}a\]
Bayes risk:
\[r(f, \hat{\theta})= \frac{b^4 \sigma ^2}{(\sigma ^2 + b^2)^2}+ \frac{\sigma ^2 b^2}{(\sigma ^2 + b^2)^2}\]



\end{problem}

\begin{problem}{3}
 
We have:
\[L(\theta, \hat{\theta})= I(\theta \neq \hat{\theta}) \Rightarrow R(\theta, \hat{\theta})= \mathbb{E}[I(\hat{\theta} \neq \theta)]= \sum I(\hat{\theta} \neq \theta)f(\theta | x)\]

Hence, to minimize $R(\hat{\theta}, \theta)$,  $\hat{\theta} $ must not be equal $\theta$ as much as possible $\Rightarrow \hat{\theta}=$ posterior mode of $f(\theta| x)$ 


\end{problem}

\begin{problem}{4}


We have:
\[L(\sigma ^2, \hat{\sigma} ^2)=\frac{\hat{\sigma} ^2}{\sigma} -1- \log(\frac{\hat{\sigma} ^2}{\sigma})\]
\[\Rightarrow R(\sigma ^2, \hat{\sigma} ^2)= \mathbb{E}[L(\sigma ^2, \hat{\sigma} ^2)]=\frac{E[bS^2]}{\sigma ^2}-1-\mathbb{E}[\log (bS^2)]+ \log(\sigma ^2)\]
Apply Jessen's inequality:
\[R(\sigma ^2, \hat{\sigma} ^2) \geq \frac{E[bS^2]}{\sigma ^2}-1-\log (\mathbb{E}[bS^2] )+ \log(\sigma ^2)\]

In addition, $\mathbb{E}[S^2]= \sigma ^2$, hence:
\[R(\sigma ^2, \hat{\sigma} ^2) \geq b -1 + \log b \]

Take the derivative of the right-hand side, we get : b=1



\end{problem}


\begin{problem}{5}
We have $L(p, \hat{p})=\big(1-\frac{\hat{p}}{p} \big)^2$ \\
Apply Jessen's inequality: $ \mathbb{E}_p[\hat{p} ^2] \geq {\mathbb{E}_p [\tilde{p}]}^2$, We get:
\[R(p, \tilde{p})=\mathbb{E}_{p}[L(p, \tilde{p})]=1-\frac{2\mathbb{E}_p[\tilde{p}]}{p}+\frac{{\mathbb{E}_p [\tilde{p}^2]}}{p^2} \geq \big(1-\frac{\mathbb{E}_p [\tilde\hat{p}]}{p} \big)^2  \] 
In addition $\big(1-\frac{\mathbb{E}_p [\tilde\hat{p}]}{p} \big)^2  \leq 1 $, Hence:
\[ inf_{\tilde{p}} sup_{p}R(p, \tilde{p})= 1\]

On the other hands:
\[R(p, \hat{p})= 1-\frac{2\mathbb{E}_p[\hat{p}]}{p}+\frac{{\mathbb{E}_p [\hat{p}^2]}}{p^2}=1\]
\[ \Rightarrow sup_{p}R(p, \hat{p})=1= inf_{\tilde{p}} sup_{p}R(p, \tilde{p})\]
Therefore, $\hat{p}$ is minimax rule

\end{problem}










\end{document}